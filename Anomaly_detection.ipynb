{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Anomaly_detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNc+r5Pkzjk/M6RzfLgFBsl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"njhT4x0rzE97"},"source":["# Install Apache Spark 3.0.0"]},{"cell_type":"code","metadata":{"id":"RZM6XcSMy4IM","executionInfo":{"status":"ok","timestamp":1633510710619,"user_tz":-120,"elapsed":18574,"user":{"displayName":"MARCO CHISCI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02314560591425702803"}}},"source":["# install Java8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# download spark3.0.0\n","!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n","# unzip it\n","!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n","# install findspark \n","!pip install -q findspark"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-sZSTxiKzbB-"},"source":["# Set Environment Variables"]},{"cell_type":"code","metadata":{"id":"DowTY2Lmzi9v","executionInfo":{"status":"ok","timestamp":1633510714371,"user_tz":-120,"elapsed":8,"user":{"displayName":"MARCO CHISCI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02314560591425702803"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v7y-c6hXzql5"},"source":["Installation Test and pyspark version"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tyr7niAHzuAF","executionInfo":{"status":"ok","timestamp":1633511147822,"user_tz":-120,"elapsed":216,"user":{"displayName":"MARCO CHISCI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02314560591425702803"}},"outputId":"e30cfe80-d6b9-461e-e1eb-45a0cb266c8a"},"source":["import findspark\n","findspark.init()\n","from pyspark.sql import Row\n","# Test\n","mylist = [\n","  {\"Hello\":\"world\"}\n","]\n","spark.createDataFrame(Row(**x) for x in mylist).show(truncate=False)\n","\n","# Check the pyspark version\n","import pyspark\n","print(pyspark.__version__)\n"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+\n","|Hello|\n","+-----+\n","|world|\n","+-----+\n","\n","3.0.0\n"]}]}]}