{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Anomaly_detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOw6QgrCzNbIxEIDV76nULb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"njhT4x0rzE97"},"source":["# Install Apache Spark 3.0.0"]},{"cell_type":"code","metadata":{"id":"RZM6XcSMy4IM","executionInfo":{"status":"ok","timestamp":1633512809378,"user_tz":-120,"elapsed":18296,"user":{"displayName":"MARCO CHISCI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02314560591425702803"}}},"source":["# install Java8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# download spark3.0.0\n","!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n","# unzip it\n","!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n","# install findspark \n","!pip install -q findspark"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-sZSTxiKzbB-"},"source":["# Set Environment Variables"]},{"cell_type":"code","metadata":{"id":"DowTY2Lmzi9v","executionInfo":{"status":"ok","timestamp":1633512809379,"user_tz":-120,"elapsed":18,"user":{"displayName":"MARCO CHISCI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02314560591425702803"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JqqvJo3i8PGC"},"source":["#Create local spark session\n"]},{"cell_type":"code","metadata":{"id":"iTk4DGI98RLW","executionInfo":{"status":"ok","timestamp":1633512815839,"user_tz":-120,"elapsed":6477,"user":{"displayName":"MARCO CHISCI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02314560591425702803"}}},"source":["import findspark\n","findspark.init()\n","from pyspark.context import SparkContext\n","from pyspark.sql.session import SparkSession\n","sc = SparkContext('local')\n","spark = SparkSession(sc)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v7y-c6hXzql5"},"source":["Installation Test and pyspark version"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tyr7niAHzuAF","executionInfo":{"status":"ok","timestamp":1633512825543,"user_tz":-120,"elapsed":9733,"user":{"displayName":"MARCO CHISCI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02314560591425702803"}},"outputId":"e237a6cd-b177-4a6a-9a62-35917b23d01d"},"source":["#create a test schema\n","from pyspark.sql.types import *\n","from pyspark.sql import Row\n","\n","schema = StructType([StructField('name', StringType()), StructField('age',IntegerType())])\n","rows = [Row(name='Severin', age=33), Row(name='John', age=48)]\n","df = spark.createDataFrame(rows, schema)\n","\n","df.printSchema()\n","df.show()\n","\n","\n","# Check the pyspark version\n","import pyspark\n","print(pyspark.__version__)\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- name: string (nullable = true)\n"," |-- age: integer (nullable = true)\n","\n","+-------+---+\n","|   name|age|\n","+-------+---+\n","|Severin| 33|\n","|   John| 48|\n","+-------+---+\n","\n","3.0.0\n"]}]}]}